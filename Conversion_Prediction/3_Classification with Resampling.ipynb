{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion Prediction : Classification with Resampling\n",
    "------\n",
    ">In this part of the project, we will try to:  \n",
    ">> analyse the effect of **balancing** the dataset using the **Resampling** techniques on the prediction performance.\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4wtUjVlLIfw"
   },
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [1. Data Preparation](#section1)\n",
    "    * [1.1. Load Data](#section21)\n",
    "    * [1.2. Predictors and Target](#section21)\n",
    "    * [1.3. Resampling](#section22)\n",
    "    * [1.4. Training and Validation sets](#section22)\n",
    "    * [1.5. Preprocessing pipeline](#section23)\n",
    "* [2. Classification](#section2)\n",
    "    * [2.1. Preliminary Analysis](#section21)\n",
    "        * [2.1.1. Statmodels logit](#section21)\n",
    "    * [2.2. Logistic Regression](#section23)\n",
    "        * [2.2.1. Model Evaluation](#section24)\n",
    "    * [2.4. Train on the whole dataset](#section25)\n",
    "* [3. Predict the target of the test set](#section2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vv1phpoALIfx",
    "tags": []
   },
   "source": [
    " #### Import useful modules ‚¨áÔ∏è‚¨áÔ∏è and Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eK8s9YTVLIfx"
   },
   "outputs": [],
   "source": [
    "# generic libs\n",
    "import os\n",
    "import pandas as pd\n",
    "from numpy import append\n",
    "from time import time\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML tools\n",
    "# pre_training tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# training tools\n",
    "import statsmodels.api as sm \n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "\n",
    "# predefined modules\n",
    "from modules import MyFunctions as MyFunct\n",
    "\n",
    "# Global parameters \n",
    "train_filepath = 'data/conversion_data_train.csv'\n",
    "test_filepath = 'data/conversion_data_test.csv'\n",
    "results_path = \"results/\"\n",
    "\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.mkdir(\"output\")\n",
    "output_path = 'output/'\n",
    "\n",
    "seed = 0\n",
    "cv = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HE-RhpScLIfz",
    "outputId": "4117338e-c644-42c2-f8a3-39129427e3bb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "dataset = pd.read_csv(train_filepath)\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  age  new_user  source  total_pages_visited  converted\n",
       "0    China   22         1  Direct                    2          0\n",
       "1       UK   21         1     Ads                    3          0\n",
       "2  Germany   20         0     Seo                   14          1\n",
       "3       US   23         1     Seo                    3          0\n",
       "4       US   28         1  Direct                    3          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictors and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_1qx9qVNLIf1"
   },
   "outputs": [],
   "source": [
    "# Separate target variable y from features X\n",
    "y = dataset['converted']\n",
    "X = dataset.drop('converted', axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iq8uS304LIf1"
   },
   "source": [
    "üóí As the dataset is **highly imbalanced**, it would be better to **resample** the observations in order to **balance** the dataset. In general, there are 2 approaches:   \n",
    "1) Under Sampling: Remove samples from the majority class.   \n",
    "2) Over Sampling: Duplicate samples from the minority class.\n",
    "\n",
    "In the current proposal we will use the **Under Sampling** approach from the library **imblearn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X, y = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iq8uS304LIf1"
   },
   "source": [
    "üóí **_Stratify_**: If we select observations from the dataset with a uniform probability distribution (**stratify = y(dataset['converted']**), we will draw observations from each class with the same probability of their occurrence in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify = y)\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.tolist()\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">üóí In the dataset, we have mixed data with both quantitative and qualitative predictors. Hence, we must define a different preprocessing pipeline for each category.\n",
    ">> 1. we will **standardize** the numerical data before training to eliminate large scales effect on the learning phase.\n",
    ">> 2. we will **encode** categorical predictors using one-hot (aka ‚Äòone-of-K‚Äô or ‚Äòdummy‚Äô) encoding scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "830CiJovLIf1"
   },
   "outputs": [],
   "source": [
    "# Create pipeline for numeric features \n",
    "#Num_X =['age', 'total_pages_visited'] \n",
    "num_X = [1,4]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create pipeline for categorical features\n",
    "#cat_X = ['country', 'new_user', 'source']\n",
    "cat_X = [0,2,3]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "# Use ColumnTranformer to make a preprocessor object \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_X),\n",
    "        ('cat', categorical_transformer, cat_X)\n",
    "    ])\n",
    "\n",
    "# Preprocessings on train set (8 cols = 2 for numerci columns + 1 for new_user + 3 for country + 2 for source)\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test  = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46pmETdjLIf2"
   },
   "source": [
    "## Preliminary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46pmETdjLIf2"
   },
   "source": [
    "### Statmodels logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LV9tpMO8LIf2"
   },
   "source": [
    "üóí **_Statmodels_**: we want to establish a preliminary analysis using the Statmodels logit function that gives a detailed results of a regression model in order to confirm what we have noticed in the EDA part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "296BLakQLIf2"
   },
   "outputs": [],
   "source": [
    "cols =preprocessor.transformers_[1][1].named_steps['encoder'].get_feature_names().tolist()\n",
    "columns = ['const','age', 'total_pages_visited'] + cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "id": "gU4xKy_mLIf2",
    "outputId": "b6643c9f-1595-457b-b105-9fd200bcd29f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.157403\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 14688</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td> 14679</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 14 Apr 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.7729</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>06:54:53</td>     <th>  Log-Likelihood:    </th> <td> -2311.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -10181.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   -2.0279</td> <td>    0.198</td> <td>  -10.226</td> <td> 0.000</td> <td>   -2.417</td> <td>   -1.639</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                 <td>   -0.5309</td> <td>    0.041</td> <td>  -13.034</td> <td> 0.000</td> <td>   -0.611</td> <td>   -0.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_pages_visited</th> <td>    4.4927</td> <td>    0.088</td> <td>   50.800</td> <td> 0.000</td> <td>    4.319</td> <td>    4.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0_Germany</th>          <td>    3.8345</td> <td>    0.244</td> <td>   15.695</td> <td> 0.000</td> <td>    3.356</td> <td>    4.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0_UK</th>               <td>    3.5782</td> <td>    0.205</td> <td>   17.455</td> <td> 0.000</td> <td>    3.176</td> <td>    3.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0_US</th>               <td>    3.2664</td> <td>    0.193</td> <td>   16.909</td> <td> 0.000</td> <td>    2.888</td> <td>    3.645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1_1</th>                <td>   -1.4625</td> <td>    0.078</td> <td>  -18.712</td> <td> 0.000</td> <td>   -1.616</td> <td>   -1.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2_Direct</th>           <td>   -0.0656</td> <td>    0.111</td> <td>   -0.591</td> <td> 0.555</td> <td>   -0.283</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2_Seo</th>              <td>    0.0261</td> <td>    0.090</td> <td>    0.291</td> <td> 0.771</td> <td>   -0.150</td> <td>    0.202</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                14688\n",
       "Model:                          Logit   Df Residuals:                    14679\n",
       "Method:                           MLE   Df Model:                            8\n",
       "Date:                Thu, 14 Apr 2022   Pseudo R-squ.:                  0.7729\n",
       "Time:                        06:54:53   Log-Likelihood:                -2311.9\n",
       "converged:                       True   LL-Null:                       -10181.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "=======================================================================================\n",
       "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  -2.0279      0.198    -10.226      0.000      -2.417      -1.639\n",
       "age                    -0.5309      0.041    -13.034      0.000      -0.611      -0.451\n",
       "total_pages_visited     4.4927      0.088     50.800      0.000       4.319       4.666\n",
       "x0_Germany              3.8345      0.244     15.695      0.000       3.356       4.313\n",
       "x0_UK                   3.5782      0.205     17.455      0.000       3.176       3.980\n",
       "x0_US                   3.2664      0.193     16.909      0.000       2.888       3.645\n",
       "x1_1                   -1.4625      0.078    -18.712      0.000      -1.616      -1.309\n",
       "x2_Direct              -0.0656      0.111     -0.591      0.555      -0.283       0.152\n",
       "x2_Seo                  0.0261      0.090      0.291      0.771      -0.150       0.202\n",
       "=======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = sm.add_constant(X_train)\n",
    "\n",
    "logit = sm.Logit(y_train,X2)\n",
    "\n",
    "logit_fit = logit.fit()\n",
    "\n",
    "logit_fit.summary(xname=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmr5pI2ZLIf3"
   },
   "source": [
    "****************************************************************                  \n",
    "> üóí **Statistical Significance (P>|z|)**: The **Resampling** confirms the **non-significance** of the predictor **source**. We may eliminate it from the prediction.\n",
    "\n",
    "> üóí **Predictors Importance (coef)**: The **Resampling** changes the ordering of the predictors and highlights the insights found in the EDA part. The predictors are ordred as follows given their importance:     \n",
    "**total_pages_visited, Country, age, Source**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsZxDMpBLIf4"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJ7v4WNjLIf5"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmr5pI2ZLIf3"
   },
   "source": [
    "> üóí We will evaluate the performance of the **LogisticRegression** classifier using the **f1_score** by the means of **k-fold Cross validation** technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting LogisticRegression is done in 1.6619296073913574s\n",
      "Classifier : LogisticRegression \n",
      "Mean_f1 : 0.9364959161839149 \n",
      "Std_f1 : 0.022319690058280755\n"
     ]
    }
   ],
   "source": [
    "scores = MyFunct.model_validation(LogisticRegression(),X_train, y_train, cv = cv, scoring = 'f1')\n",
    "print(f\"Classifier : {scores[0]} \\nMean_f1 : {scores[1]} \\nStd_f1 : {scores[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmr5pI2ZLIf3"
   },
   "source": [
    "> üóí The old values of the **f1_score** are:  \n",
    "Mean : 0.7644634617786664    \n",
    "Std : 0.04540174813269441    \n",
    "\n",
    "The **f1_score** is increased by **17%**. Not bad!! \n",
    "\n",
    ">> The **Resampling** gives better scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wjizX1QLIf6"
   },
   "source": [
    "## Train on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting Resampling_LogisticRegression is done in 0.06558585166931152s\n"
     ]
    }
   ],
   "source": [
    "# train the model on the whole data\n",
    "X1 = append(X_train,X_test,axis=0)\n",
    "y1 = append(y_train,y_test)\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "name = 'Resampling_'+str(lr_model).split('(')[0]\n",
    "\n",
    "t0= time()\n",
    "lr_model.fit(X1, y1)\n",
    "print(f'fitting {name} is done in {time() - t0}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf7ofr1eLIf6"
   },
   "source": [
    "# Predict the target of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Tr4CEaPzzbP-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction set (without labels) : (31620, 5)\n"
     ]
    }
   ],
   "source": [
    "# Read data without labels\n",
    "X_without_labels = pd.read_csv(test_filepath)\n",
    "print('Prediction set (without labels) :', X_without_labels.shape)\n",
    "\n",
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "X_without_labels = X_without_labels.values\n",
    "\n",
    "# preprocess\n",
    "X_without_labels  = preprocessor.transform(X_without_labels)\n",
    "\n",
    "# predict\n",
    "y_pred = lr_model.predict(X_without_labels)\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=['conversion'])\n",
    "y_pred_df.to_csv(output_path+'conversion_data_test_predictions_'+name+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_Classification (3).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
